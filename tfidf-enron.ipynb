{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document(object):\n",
    "    def __init__(self, data):\n",
    "        self.documentId = data['documentId']\n",
    "        self.time = data['time']\n",
    "        self.sender = data['sender']\n",
    "        self.sender_id = data['sender_id']\n",
    "        self.body = data['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import email\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def clean_body(body):\n",
    "    patterns = [\n",
    "        \"-----Original Message-----\",\n",
    "        \"***************************\",\n",
    "        \"----------------------\",\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        index = body.find(pattern)\n",
    "        if index != -1:\n",
    "            body = body[:index]\n",
    "    return body.strip()\n",
    "\n",
    "\n",
    "users = {}\n",
    "corpus = defaultdict(list)\n",
    "\n",
    "def load_users():\n",
    "    with open(os.path.join(DATA_DIR, \"users.json\")) as f:\n",
    "        for k, v in json.loads(f.read()).items():\n",
    "            users[v] = k\n",
    "\n",
    "def load_corpus():\n",
    "    index = 0\n",
    "    with open(os.path.join(DATA_DIR, \"messages.json\")) as f:\n",
    "        data = json.loads(f.read())\n",
    "        for msg in data:\n",
    "            body = clean_body(msg[\"message\"])\n",
    "            if not body:\n",
    "                continue\n",
    "            corpus[msg[\"sender\"]].append(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_users()\n",
    "load_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def sanitize(text):\n",
    "    return re.sub('[^a-z]+', ' ', text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "def build_inverted_index(corpus):\n",
    "    index = defaultdict(dict)\n",
    "    for sender, bodies in corpus.items():\n",
    "        words_counter = Counter(tokenize(sanitize(\" \".join(bodies))))\n",
    "        for word, count in words_counter.items():\n",
    "            index[word][sender] = count\n",
    "    return index\n",
    "\n",
    "\n",
    "def build_sender_word_count(corpus):\n",
    "    index = defaultdict(dict)\n",
    "    for sender, bodies in corpus.items():\n",
    "        words_counter = Counter(tokenize(sanitize(\" \".join(bodies))))\n",
    "        for word, count in words_counter.items():\n",
    "            index[sender][word] = count\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = build_inverted_index(corpus)\n",
    "sender_word_count = build_sender_word_count(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term Frequency\n",
    "How frequently a user uses the term\n",
    "\n",
    "### Inverse Document Frequency\n",
    "log(Number of users/number of users that uses the word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set([\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sender_vocab = defaultdict(set)\n",
    "for word, sender_count in inverted_index.items():\n",
    "    senders = sender_count.keys()\n",
    "    for sender in senders:\n",
    "        sender_vocab[sender].add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def tfidf_v1(word, sender):\n",
    "    try:\n",
    "        tf = sender_word_count[sender][word]\n",
    "        idf = math.log(len(users)/len(inverted_index[word]), math.e)\n",
    "        return tf * idf\n",
    "    except KeyError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_informative_words_sender(sender):\n",
    "    word_tfidf = []\n",
    "    for word in sender_vocab[sender]:\n",
    "        if word in stopwords:\n",
    "            continue\n",
    "        word_tfidf.append((word, tfidf_v1(word, sender)))\n",
    "    return sorted(word_tfidf, key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('amazon', 3422.2071624364876),\n",
       " ('image', 2535.542984866394),\n",
       " ('obidos', 1380.1306201893176),\n",
       " ('mk', 1294.2466743249338),\n",
       " ('cust', 1239.8002185491016),\n",
       " ('hol', 1211.7536688134012),\n",
       " ('com', 1149.944468059166),\n",
       " ('ref', 1081.2836962747208),\n",
       " ('exec', 1053.2670613620144),\n",
       " ('preferences', 952.1873154123343)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_informative_words_sender(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_random_email():\n",
    "    sender = random.choice(list(corpus.keys()))\n",
    "    return random.choice(corpus[sender]), sender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Make $2000-$6000 Per Week From Home In The Next 90 Days Are You Looking To Make More Money? If you are currently looking to make more money or to add to your income or currently unemployed and have between 2 - 8 hrs per day. We have something for you that will change your current financial situation. It is absolutely 100% FREE, Don't miss out on a real opportunity! CLICK HERE FOR MORE INFORMATION\",\n",
       " 5779)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_email()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def who_wrote_it_v1(text):\n",
    "    sender_tfidfs = defaultdict(list)\n",
    "    tokens = tokenize(sanitize(text))\n",
    "    for token in tokens:\n",
    "        if token in stopwords:\n",
    "            continue\n",
    "        for sender in inverted_index[token]:\n",
    "            tfidf = tfidf_v1(token, sender)\n",
    "            sender_tfidfs[sender].append(tfidf)\n",
    "    return sorted(sender_tfidfs.keys(), key=lambda x: max(sender_tfidfs[x]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38343 False\n"
     ]
    }
   ],
   "source": [
    "text, actual_sender = get_random_email()\n",
    "who = who_wrote_it_v1(text)\n",
    "print(actual_sender, actual_sender in who)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
